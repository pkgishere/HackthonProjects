**DareDevil – Giving vision to those without it.**


Bitcamp ​ 2018 (University of Maryland, College Park)
Winner: 
​**Best Accessibility Hack by MICROSOFT and Best Philanthropic Hack by BLOOMBERG**


Created a Natural language processing application to help visually impaired person.
The application in voice-assisted and in the real-time process the camera feed and summarizes the
document captured using the device.


Problem Statement:
Most of the data which is accessible to general public, is in not present in the Braille or in any audio
format. The closest feature before this application was to use camera to read what is written. It
wastes a lot of time for a visually impaired person as he/she has to listen to whole data and then
decide he or she is interested in that.


Solution Created:
We created an application using Computer Vision, Natural Language Processing, Machine Learning
to Summarize the document using Latent Dirichlet Allocation so that a blind person can hear a single
line summary to decide he wants to read complete document.


Step by Step Working:
Creating a hardware which has a camera and integrated it with Google Assistant, so that it
can take a photo using Voice command.
Store and Process that Photo on Cloud then performed text extraction from the Image.
From Extracted Text, applied Latent Dirichlet Allocation Algorithm to determine what is
unique about the current document.
Created two summaries, single line and detailed summary of the text.
Integrating the Application with Google Assistant so that it can interact with the user about
the document.
Storing the document and it’s summary for retrieval in future using Voice assistance.



Team and individual roles:
Ishan Dikshit (​ishan.juit@gmail.com​) : Integrated Vision API, Coded for Latent Dirichlet
Allocation, Tested and debugged front end React Native Application, Cloud Integration and
deployment.
Prashant Garg (​pkgishere@gmail.com​): Integrated Google Assistant and Liked Google Mini
using Dialog-Flow, Developed Intent Model, Created webhook for back-end web Service
Integration.
Sanchit Narang (​sanchit.narang94@gmail.com​): Developed a front-end React Native App
which takes the photo and send it to the Cloud. Also Created a hardware to setup camera.
Suchir Inamdar (​inamdar.shuchir77@gmail.com​): Worked on Integration of Voice with
Back-end using node.js and tested the system.

